{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation of a dataset for span-mlm\n",
    "\n",
    "Adds noise to a given dataset by masking random spans of tokens. The resulting dataset can be used for span-masked-language-modelling with the notebook [mt5_smlm_train.ipynb](mt5_smlm_train.ipynb)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdaefa3b7858202f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from mt5_smlm_scripts import DataCollatorForT5MLM, compute_input_and_target_lengths, create_smlm_example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27a52140cff95582"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# ds = load_from_disk(\"german_ds\")\n",
    "ds = load_from_disk(\"german_ds_shuffled\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22ff3dc21405f4bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "842976a854fb9b22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the previously trained german SentencePiece tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b182d73ea53bcf04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer_id = \"german_tokenizer\"\n",
    "model_id = \"google/mT5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6afc20aba6844b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_length = 128\n",
    "\n",
    "def tokenize(input):\n",
    "  outputs = tokenizer(\n",
    "      input['text'],\n",
    "      truncation=True,\n",
    "      max_length=context_length,\n",
    "      return_overflowing_tokens=True,\n",
    "      return_length=True\n",
    "  )\n",
    "  input_batch = []\n",
    "  for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "    if length == context_length:\n",
    "        input_batch.append(input_ids)\n",
    "  return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "tokenized_dataset = ds.map(\n",
    "      tokenize, batched=True, remove_columns=ds[\"train\"].column_names\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "max_seq_length = context_length\n",
    "# these parameters determine how much noise there will be in the span masked dataset\n",
    "mlm_probability = 0.15\n",
    "mean_noise_span_length = 3.0\n",
    "\n",
    "# ===============================================================\n",
    "# From\n",
    "# https://github.com/huggingface/transformers/blob/main/examples/flax/language-modeling/run_t5_mlm_flax.py\n",
    "expanded_inputs_length, targets_length = compute_input_and_target_lengths(\n",
    "    inputs_length=max_seq_length,\n",
    "    noise_density=mlm_probability,\n",
    "    mean_noise_span_length=mean_noise_span_length,\n",
    ")\n",
    "\n",
    "\n",
    "# Main data processing function that will concatenate all texts from our dataset and generate chunks of expanded_inputs_length.\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= expanded_inputs_length:\n",
    "        total_length = (total_length // expanded_inputs_length) * expanded_inputs_length\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i: i + expanded_inputs_length] for i in range(0, total_length, expanded_inputs_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# tokenized_dataset = ds[\"train\"].select(range(100000)).map(\n",
    "tokenized_dataset_grouped = tokenized_dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    # num_proc=data_args.preprocessing_num_workers,\n",
    "    # load_from_cache_file=not data_args.overwrite_cache,\n",
    ")\n",
    "# ==============================================================="
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2573dd8c1c41271"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_seq_length = 128\n",
    "mlm_probability = 0.15\n",
    "mean_noise_span_length = 3.0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64f45bcb93164261"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "collator = DataCollatorForT5MLM(\n",
    "    tokenizer=tokenizer,\n",
    "    input_length=max_seq_length,\n",
    "    target_length=targets_length,\n",
    "    noise_density=mlm_probability,\n",
    "    mean_noise_span_length=mean_noise_span_length,\n",
    "    pad_token_id=model.config.pad_token_id,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id)\n",
    "\n",
    "smlm_dataset = tokenized_dataset_grouped.map(\n",
    "    lambda x: create_smlm_example(x, collator),\n",
    "    batched=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d74d8f2fd6fb64c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_path = \"german_ds_smlm_noised\"\n",
    "smlm_dataset.save_to_disk(save_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b28174fce7243e87"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
