{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scripts import prepare_mt5_finetuning, plot_loss, evaluate_model, save_model, save_tokenizer\n",
    "import torch\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7dc82b4d3828c67"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up the configuration of the mT5 model that should be trained here. Add multiple configurations to do multiple training runs back to back."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc4d73e6b6c9b1cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595288b9-8085-4556-b96a-4250a649ec62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hf_token = None # set huggingface token for hub download and upload\n",
    "hub_name= None # set huggingface username\n",
    "\n",
    "# Set train, validation and test files before training\n",
    "file_train = \"\" \n",
    "file_val = \"\"\n",
    "file_test = \"\"\n",
    "\n",
    "runs = [\n",
    "    {\n",
    "        \"model_id\": \"google/mT5-small\",\n",
    "        \"finetune_id\": \"mT5-small-test\",\n",
    "        \"file_train\": file_train,\n",
    "        \"file_val\" : file_val,\n",
    "        \"tokenizer_id\": \"google/mT5-small\",\n",
    "        \"trim_model\": False,\n",
    "        \"file_test\" : file_test,\n",
    "        \"lr\": 1e-3,\n",
    "        \"epochs\": 1,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sets up the model for the training process and then starts the process by calling trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "388981c6a96c4269"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ab43b-7795-471a-a9f5-cde7cd88d273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for run in runs:\n",
    "    trainer, tokenizer = prepare_mt5_finetuning(\n",
    "        model_id=run[\"model_id\"],\n",
    "        tokenizer_id=run[\"tokenizer_id\"],\n",
    "        trim_model=run[\"trim_model\"],\n",
    "        finetuned_model_id=run[\"finetune_id\"],\n",
    "        file_train=run[\"file_train\"],\n",
    "        file_val=run[\"file_val\"],\n",
    "        learning_rate=run[\"lr\"],\n",
    "        num_train_epochs=run[\"epochs\"],\n",
    "        hf_token=hf_token,\n",
    "        push_to_hub=False,\n",
    "        # unfreeze_embedding=True,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    save_model(trainer, run[\"finetune_id\"], hf_token=hf_token, hub_name=hub_name)\n",
    "    if run[\"trim_model\"]:\n",
    "        save_tokenizer(tokenizer, run[\"finetune_id\"], hf_token=hf_token, hub_name=hub_name)\n",
    "    with open(f'{run[\"finetune_id\"]}/{run[\"finetune_id\"]}_run_stats.json', \"w\") as f:\n",
    "        json.dump(run, f)\n",
    "        f.close()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Starts the evaluation process. By default, this will generate predictions for the whole test-set, but the amount of predictions can be limited by n."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d8bc81b4c0fc53a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff0f4b2e53919d",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    print(run)\n",
    "    evaluate_model(\n",
    "        peft_model_id=run[\"finetune_id\"], \n",
    "        base_model_id=run[\"model_id\"],\n",
    "        tokenizer_id=run[\"tokenizer_id\"], \n",
    "        file_test=run[\"file_test\"], \n",
    "        save_dir=run[\"finetune_id\"], \n",
    "        # n=50,\n",
    "        hf_token=hf_token,\n",
    "        hub_name=hub_name,\n",
    "        resize_embedding=run[\"trim_model\"],\n",
    "    )\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
